The data is from an experiment called vt3

In this experiment, participants went through 68 stimuli in 39 trials (some trial had two stimuli). The same set of questions were asked for each time participants went through a stimuli. Therefore the same set of questions were repeated 68 times.

Beyond these questions, there are also metadata and other questions that participants only asked once throughout the experiment (like their age).

Four datatypes were used in this descritpion:
Numeric: Integer, floats and any datatype that is used to represent numbers and/or continous variables.
Binary: Yes or no. The actual data might be a number (0, 1) or a string.
Factor: Used to represent categories (e.g., experiment conditions) or multiple choice answers (e.g., gender) that has a finite number of values. The actual data might be a number (0, 1) or a string. 

Here are descriptions of each data file.

########## vt3 raw data ##########
Raw data with minimum change from its original form. 

##Suggested Use##
Decapitator to take out the two of the three header rows
After decapitator, janitor can take out unwanted columns and executioner can take out unwanted rows

##Columns of Interest##
Col. 7 Finished: Binary. Whether the participant finished the survey. We should keep row that says "True."

Col. 9 Response ID: String. A unique ID assigned to a participant by Qualtrics. Each row is a single participant. We will use this column to track participants in all datasets.

Col. 12 DistributionChannel: Factor. It tracks where the participant came form. For our purposes, executioner should take out anything that says "preview.

Col. 14 Q_RecaptchaScore: Numeric. A score generated by Qualtrics to indicate the likelihood of this participant is a bot instead of human. The higer the score, the more likely to be human. Executioner should remove any row with a score lower than the threshold set by the user. It can also optionally remove any row without a score.

Col. 15 to 830: data for the 68 stimuli (39 trials). Each stimulus has 12 questions/columns. Here is a breakdown:
	Col. 1 & 2 of each stimuli: likelihood. Numeric with range 0 - 100. Only one of these two 	columns should have a value.
	Col. 3 & 4 of each stimuli: severity. Numeric with range 0 - 100. Only one of these two 	columns should have a value.
	Col. 5 of each stimuli: pretrust. Numeric with range 0 - 100.
	Col. 6 of each stimuli: decision. Factor. Multiple choice question with four answers. It 	was be coded binary. Don't worry about it here.
	Col. 7 to 11 of each stimuli: We don't need to worry about these
	Col. 12 of each stimuli: outcometrust. Numeric with range 0 - 100.

Col. 852 Do you have any form of color blindness?: Factor. This is a multiple choice question. It was not used as an attention check but we can use it as a stand-in for a multiple choce attention check. We can make it so that participants who selected "No" are kept and everyone else are dropped.

Col. 856 What was the natural hazard in this study?: String. A text-entry attention check question. The correct answer is "tornado" or "storm." Typos, plurals and capitalization of one or more letters should also be accepted.

Col. 860 & 868 condition & likelihoodCB: Factor. Metadata indicating a participants' assigned condition. Condition has three possible values (polygon, red, tabular) while likelihoodCB has two possible values (likelhood, severity). They can be used in frankenstein as part of "group by" to aggregate data.

########## vt3 data cleaned not converted or aggregated ##########
Cleaned data with all the unwanted rows/participants removed and one header remains. It has the same columns as the raw data. It is also a "wide" format data as each row is one participant and their responses in all stimuli.
Participants were cleaned based on the following criteria:
1. Previews removed (2 removed)
2. Unfinished removed (5 removed)
3. Recaptcha score lower than 0.7 removed. However Participants who had no score were kept. (4 removed)
4. Text entry attention check failed. (4 removed)
5. Two other criteria unconcerned to us that removed 3 rows.
Our program does not need to handle step 5. It should handle step 1 to 4, which removed 15 participants.

##Suggested Use##
Janitor to take out more columns as tests
Long-wide concerter to convert the data where each stimulus is a row.
Frankenstein to aggregate the data from this dataset.

########## vx3 data long format.csv ##########
Long format data converted from the cleaned dataset. This dataset contains only the data for each stimuli. It does not include any participant level data (questions that were asked only once instead of 68 times). However if we want we can use left joint to add these participant level data.

##Suggested Use##
Long-wide concerter to check whether the converted data match with this dataset.
Frankenstein to aggregate the data from this dataset.

##Columns of Interest##
Col. 1 Response ID
Col. 2 stimuli: each participant should have 68 stimuli
Col. 3 trial: each participant should have 39 trials. Some trials had more than one stimulus
Col. 4 timepoint: each trial should have either one or two timepoints corresponding to one or two stimuli of the trial
Col. 5 likelihood: Question asked at each stimuli.
Col. 6 severity: Question asked at each stimuli.
Col. 7 pretrust: Question asked at each stimuli.
Col. 8 decision: Question asked at each stimuli. Coded binary from the four possible answers. Don't worry about this one.
Col. 9 outcometrust: Question asked at each stimuli. 
Col. 10 prob: Metadata. Prob is a property of a stimulus. It has 6 possible values: 0, 10, 30, 50, 70, 90.

########## vt3 data aggregated by code ##########
Dataset aggregated from the long format dataset by "Response ID." Each participant has one row. Some participant level data were also added using left joint.

##Suggested Use##
Frankenstein can use this dataset in testing.
Janitor to take out unwanted columns (1 to 8)

##Columns of Interest##
Col. 1 to 8: Participant level data
Col. 9 Response ID
Col. 10 likelihoodoverall: mean likelihood calculated from all 68 stimuli of a participant
Col. 11 severityoverall: mean severity calculated from all 68 stimuli of a participant
Col. 12 outcometrustoverall: mean outcometrust calculated from all 68 stimuli of a participant

########## vt3 data aggregated by code and prob ##########
Dataset aggregated from the long format dataset by "Response ID" and "prob." Each participant has one row.
##Suggested Use##
Frankenstein can use this dataset in testing.

##Columns of Interest##
Col. 1 Response ID
Col. 2 Prob
Col. 3 likelihoodoverall: mean likelihood calculated from all 68 stimuli of a participant
Col. 4 severityoverall: mean severity calculated from all 68 stimuli of a participant
Col. 5 outcometrustoverall: mean outcometrust calculated from all 68 stimuli of a participant



